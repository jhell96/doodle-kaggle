{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ce6d2aa7de1fa341144def7d3a5b1ffdea26bc91"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import os\n",
    "import ast\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [16, 10]\n",
    "plt.rcParams['font.size'] = 14\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import NASNetMobile, MobileNet\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "from joblib import Parallel, delayed\n",
    "from functools import partial\n",
    "import time\n",
    "start = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "978b1e827e598c53df3ef09838a6d85591d83052"
   },
   "outputs": [],
   "source": [
    "DP_DIR = ''\n",
    "INPUT_DIR = ''\n",
    "\n",
    "BASE_SIZE = 256\n",
    "NCSVS = 100\n",
    "NCATS = 340\n",
    "np.random.seed(seed=1987)\n",
    "tf.set_random_seed(seed=1987)\n",
    "\n",
    "def f2cat(filename: str) -> str:\n",
    "    return filename.split('.')[0]\n",
    "\n",
    "def list_all_categories():\n",
    "    files = os.listdir(os.path.join(INPUT_DIR, '../../data/train_simplified'))\n",
    "    return sorted([f2cat(f) for f in files], key=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b2fcd1a08ae1ae0619be38a113a244eb6515b63b"
   },
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=3):\n",
    "    \"\"\"\n",
    "    Source: https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "    \"\"\"\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=3):\n",
    "    \"\"\"\n",
    "    Source: https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n",
    "\n",
    "def preds2catids(predictions):\n",
    "    return pd.DataFrame(np.argsort(-predictions, axis=1)[:, :3], columns=['a', 'b', 'c'])\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "54e5f0c637195b6624e2f3e6db5e7f8990e14eb7"
   },
   "outputs": [],
   "source": [
    "#The number of images originially used by the kernel\n",
    "#I keep it the same for fair comparison \n",
    "MAGIC_CONSTANT = 800 * 680  \n",
    "batchsize = 2048\n",
    "STEPS = MAGIC_CONSTANT//batchsize \n",
    "EPOCHS = 16\n",
    "size = 64\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "0860ec35bee03f0c5cd21202dc7471c2d201cf5f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 65, 65, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 32, 32, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 32, 32, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 32, 32, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 16, 16, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 16, 16, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 16, 16, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 8, 8, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 8, 8, 256)         32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 8, 8, 256)         65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 4, 4, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 4, 4, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 4, 4, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 4, 4, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 4, 4, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 4, 4, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 4, 4, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 2, 2, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 2, 2, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 2, 2, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 2, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 340)         348500    \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 1, 1, 340)         0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 340)               0         \n",
      "=================================================================\n",
      "Total params: 3,576,788\n",
      "Trainable params: 3,554,900\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model = NASNetMobile(input_shape=(size, size, 1), weights=None, classes=NCATS)\n",
    "model = MobileNet(input_shape=(size, size, 1), alpha=1., weights=None, classes=NCATS)\n",
    "model.compile(optimizer=Adam(lr=0.002), loss='categorical_crossentropy',\n",
    "              metrics=[categorical_crossentropy, categorical_accuracy, top_3_accuracy])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "f6455bf9555b8381b6a4292098a64a0eb7ff54dc"
   },
   "outputs": [],
   "source": [
    "def draw_cv2(raw_strokes, size=256, lw=6, time_color=True):\n",
    "    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n",
    "    for t, stroke in enumerate(raw_strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            color = 255 - min(t, 10) * 13 if time_color else 255\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]),\n",
    "                         (stroke[0][i + 1], stroke[1][i + 1]), color, lw)\n",
    "    if size != BASE_SIZE:\n",
    "        return cv2.resize(img, (size, size))\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def get_input(df, size, lw, time_color):\n",
    "    df['drawing'] = df['drawing'].apply(ast.literal_eval)\n",
    "    x = np.zeros((len(df), size, size, 1))\n",
    "    for i, raw_strokes in enumerate(df.drawing.values):\n",
    "        x[i, :, :, 0] = draw_cv2(raw_strokes, size=size, lw=lw,\n",
    "                                 time_color=time_color)\n",
    "    x = preprocess_input(x).astype(np.float32)\n",
    "    y = keras.utils.to_categorical(df.y, num_classes=NCATS)\n",
    "    return x, y\n",
    "\n",
    "    \n",
    "def image_generator_xd(size, batchsize, ks, lw=6, time_color=True):\n",
    "    partial_get_input = partial(get_input, size = size, lw=lw, time_color=time_color)\n",
    "    while True:\n",
    "        for k in np.random.permutation(ks):\n",
    "            filename = os.path.join(DP_DIR, 'full_train/train_k{}.csv.gz'.format(k))\n",
    "            chunks = list(pd.read_csv(filename, chunksize=batchsize))\n",
    "            batches = Parallel(n_jobs=-1)(delayed(partial_get_input)(chunk) for chunk in chunks)\n",
    "            for batch in batches:\n",
    "                yield batch \n",
    "                \n",
    "def df_to_image_array_xd(df, size, lw=6, time_color=True):\n",
    "    df['drawing'] = df['drawing'].apply(ast.literal_eval)\n",
    "    x = np.zeros((len(df), size, size, 1))\n",
    "    for i, raw_strokes in enumerate(df.drawing.values):\n",
    "        x[i, :, :, 0] = draw_cv2(raw_strokes, size=size, lw=lw, time_color=time_color)\n",
    "    x = preprocess_input(x).astype(np.float32)\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "98ff512e1a1b5e86e86d9eef4127525bedf3b9e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34000, 64, 64, 1) (34000, 340)\n",
      "Validation array memory 0.52 GB\n"
     ]
    }
   ],
   "source": [
    "valid_df = pd.read_csv(os.path.join(DP_DIR, 'train_k{}.csv.gz'.format(NCSVS - 1)), nrows=34000)\n",
    "x_valid = df_to_image_array_xd(valid_df, size)\n",
    "y_valid = keras.utils.to_categorical(valid_df.y, num_classes=NCATS)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print('Validation array memory {:.2f} GB'.format(x_valid.nbytes / 1024.**3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "d80ad7f4d378ea7f30479221d604eeeed559cae4"
   },
   "outputs": [],
   "source": [
    "train_datagen = image_generator_xd(size=size, batchsize=batchsize, ks=range(NCSVS - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.50601053237915\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for i in range(100):\n",
    "    a = next(train_datagen)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.83713412284851\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "da72d70fc1781e80427d45a80c07b3571dda0b36",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 1.0317 - categorical_crossentropy: 1.0317 - categorical_accuracy: 0.7351 - top_3_accuracy: 0.8877\n",
      "Epoch 00001: val_loss improved from inf to 1.12168, saving model to model\n",
      "265/265 [==============================] - 324s 1s/step - loss: 1.0316 - categorical_crossentropy: 1.0316 - categorical_accuracy: 0.7351 - top_3_accuracy: 0.8877 - val_loss: 1.1217 - val_categorical_crossentropy: 1.1217 - val_categorical_accuracy: 0.7151 - val_top_3_accuracy: 0.8754\n",
      "Epoch 2/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 1.0231 - categorical_crossentropy: 1.0231 - categorical_accuracy: 0.7372 - top_3_accuracy: 0.8894\n",
      "Epoch 00002: val_loss did not improve from 1.12168\n",
      "265/265 [==============================] - 324s 1s/step - loss: 1.0231 - categorical_crossentropy: 1.0231 - categorical_accuracy: 0.7371 - top_3_accuracy: 0.8894 - val_loss: 3.1170 - val_categorical_crossentropy: 3.1170 - val_categorical_accuracy: 0.3736 - val_top_3_accuracy: 0.5760\n",
      "Epoch 3/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 1.0319 - categorical_crossentropy: 1.0319 - categorical_accuracy: 0.7351 - top_3_accuracy: 0.8878\n",
      "Epoch 00003: val_loss did not improve from 1.12168\n",
      "265/265 [==============================] - 324s 1s/step - loss: 1.0317 - categorical_crossentropy: 1.0317 - categorical_accuracy: 0.7352 - top_3_accuracy: 0.8879 - val_loss: 3.0845 - val_categorical_crossentropy: 3.0845 - val_categorical_accuracy: 0.3608 - val_top_3_accuracy: 0.5681\n",
      "Epoch 4/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 1.0091 - categorical_crossentropy: 1.0091 - categorical_accuracy: 0.7412 - top_3_accuracy: 0.8912\n",
      "Epoch 00004: val_loss did not improve from 1.12168\n",
      "265/265 [==============================] - 358s 1s/step - loss: 1.0090 - categorical_crossentropy: 1.0090 - categorical_accuracy: 0.7412 - top_3_accuracy: 0.8913 - val_loss: 1.2046 - val_categorical_crossentropy: 1.2046 - val_categorical_accuracy: 0.6899 - val_top_3_accuracy: 0.8630\n",
      "Epoch 5/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.9959 - categorical_crossentropy: 0.9959 - categorical_accuracy: 0.7438 - top_3_accuracy: 0.8931\n",
      "Epoch 00005: val_loss did not improve from 1.12168\n",
      "265/265 [==============================] - 324s 1s/step - loss: 0.9960 - categorical_crossentropy: 0.9960 - categorical_accuracy: 0.7438 - top_3_accuracy: 0.8930 - val_loss: 3.6584 - val_categorical_crossentropy: 3.6584 - val_categorical_accuracy: 0.2666 - val_top_3_accuracy: 0.4411\n",
      "Epoch 6/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 1.0143 - categorical_crossentropy: 1.0143 - categorical_accuracy: 0.7387 - top_3_accuracy: 0.8910\n",
      "Epoch 00006: val_loss improved from 1.12168 to 1.06984, saving model to model\n",
      "265/265 [==============================] - 324s 1s/step - loss: 1.0144 - categorical_crossentropy: 1.0144 - categorical_accuracy: 0.7387 - top_3_accuracy: 0.8909 - val_loss: 1.0698 - val_categorical_crossentropy: 1.0698 - val_categorical_accuracy: 0.7246 - val_top_3_accuracy: 0.8844\n",
      "Epoch 7/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.9890 - categorical_crossentropy: 0.9890 - categorical_accuracy: 0.7460 - top_3_accuracy: 0.8937\n",
      "Epoch 00007: val_loss did not improve from 1.06984\n",
      "265/265 [==============================] - 360s 1s/step - loss: 0.9887 - categorical_crossentropy: 0.9887 - categorical_accuracy: 0.7460 - top_3_accuracy: 0.8937 - val_loss: 3.2093 - val_categorical_crossentropy: 3.2093 - val_categorical_accuracy: 0.3244 - val_top_3_accuracy: 0.5185\n",
      "Epoch 8/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.9785 - categorical_crossentropy: 0.9785 - categorical_accuracy: 0.7480 - top_3_accuracy: 0.8957\n",
      "Epoch 00008: val_loss did not improve from 1.06984\n",
      "265/265 [==============================] - 323s 1s/step - loss: 0.9784 - categorical_crossentropy: 0.9784 - categorical_accuracy: 0.7480 - top_3_accuracy: 0.8957 - val_loss: 2.9709 - val_categorical_crossentropy: 2.9709 - val_categorical_accuracy: 0.3569 - val_top_3_accuracy: 0.5655\n",
      "Epoch 9/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.9707 - categorical_crossentropy: 0.9707 - categorical_accuracy: 0.7496 - top_3_accuracy: 0.8967\n",
      "Epoch 00009: val_loss improved from 1.06984 to 1.00736, saving model to model\n",
      "265/265 [==============================] - 324s 1s/step - loss: 0.9705 - categorical_crossentropy: 0.9705 - categorical_accuracy: 0.7496 - top_3_accuracy: 0.8968 - val_loss: 1.0074 - val_categorical_crossentropy: 1.0074 - val_categorical_accuracy: 0.7405 - val_top_3_accuracy: 0.8931\n",
      "Epoch 10/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.9278 - categorical_crossentropy: 0.9278 - categorical_accuracy: 0.7590 - top_3_accuracy: 0.9028\n",
      "Epoch 00010: val_loss did not improve from 1.00736\n",
      "265/265 [==============================] - 323s 1s/step - loss: 0.9279 - categorical_crossentropy: 0.9279 - categorical_accuracy: 0.7590 - top_3_accuracy: 0.9028 - val_loss: 1.1603 - val_categorical_crossentropy: 1.1603 - val_categorical_accuracy: 0.7039 - val_top_3_accuracy: 0.8681\n",
      "Epoch 11/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.9305 - categorical_crossentropy: 0.9305 - categorical_accuracy: 0.7584 - top_3_accuracy: 0.9021\n",
      "Epoch 00011: val_loss did not improve from 1.00736\n",
      "265/265 [==============================] - 358s 1s/step - loss: 0.9303 - categorical_crossentropy: 0.9303 - categorical_accuracy: 0.7584 - top_3_accuracy: 0.9021 - val_loss: 1.0345 - val_categorical_crossentropy: 1.0345 - val_categorical_accuracy: 0.7326 - val_top_3_accuracy: 0.8896\n",
      "Epoch 12/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.9381 - categorical_crossentropy: 0.9381 - categorical_accuracy: 0.7565 - top_3_accuracy: 0.9010\n",
      "Epoch 00012: val_loss did not improve from 1.00736\n",
      "265/265 [==============================] - 323s 1s/step - loss: 0.9378 - categorical_crossentropy: 0.9378 - categorical_accuracy: 0.7565 - top_3_accuracy: 0.9011 - val_loss: 1.0309 - val_categorical_crossentropy: 1.0309 - val_categorical_accuracy: 0.7353 - val_top_3_accuracy: 0.8908\n",
      "Epoch 13/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.9244 - categorical_crossentropy: 0.9244 - categorical_accuracy: 0.7607 - top_3_accuracy: 0.9033\n",
      "Epoch 00013: val_loss improved from 1.00736 to 1.00352, saving model to model\n",
      "265/265 [==============================] - 324s 1s/step - loss: 0.9242 - categorical_crossentropy: 0.9242 - categorical_accuracy: 0.7608 - top_3_accuracy: 0.9033 - val_loss: 1.0035 - val_categorical_crossentropy: 1.0035 - val_categorical_accuracy: 0.7429 - val_top_3_accuracy: 0.8921\n",
      "Epoch 14/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.9173 - categorical_crossentropy: 0.9173 - categorical_accuracy: 0.7621 - top_3_accuracy: 0.9046\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.00352\n",
      "265/265 [==============================] - 361s 1s/step - loss: 0.9172 - categorical_crossentropy: 0.9172 - categorical_accuracy: 0.7622 - top_3_accuracy: 0.9046 - val_loss: 4.8427 - val_categorical_crossentropy: 4.8427 - val_categorical_accuracy: 0.1570 - val_top_3_accuracy: 0.2881\n",
      "Epoch 15/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8897 - categorical_crossentropy: 0.8897 - categorical_accuracy: 0.7700 - top_3_accuracy: 0.9078\n",
      "Epoch 00015: val_loss improved from 1.00352 to 0.91152, saving model to model\n",
      "265/265 [==============================] - 323s 1s/step - loss: 0.8894 - categorical_crossentropy: 0.8894 - categorical_accuracy: 0.7700 - top_3_accuracy: 0.9078 - val_loss: 0.9115 - val_categorical_crossentropy: 0.9115 - val_categorical_accuracy: 0.7645 - val_top_3_accuracy: 0.9041\n",
      "Epoch 16/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8773 - categorical_crossentropy: 0.8773 - categorical_accuracy: 0.7735 - top_3_accuracy: 0.9096\n",
      "Epoch 00016: val_loss improved from 0.91152 to 0.89437, saving model to model\n",
      "265/265 [==============================] - 324s 1s/step - loss: 0.8772 - categorical_crossentropy: 0.8772 - categorical_accuracy: 0.7735 - top_3_accuracy: 0.9096 - val_loss: 0.8944 - val_categorical_crossentropy: 0.8944 - val_categorical_accuracy: 0.7682 - val_top_3_accuracy: 0.9073\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5,\n",
    "                      min_delta=0.005, mode='max', cooldown=3, verbose=1),\n",
    "    ModelCheckpoint(filepath='model', verbose=1, save_best_only=True)\n",
    "]\n",
    "hists = []\n",
    "hist = model.fit_generator(\n",
    "    train_datagen, steps_per_epoch=STEPS, epochs=EPOCHS, verbose=1,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks = callbacks\n",
    ")\n",
    "hists.append(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "ada344bf3454765298e7b7ed7861c82bca2d2084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8649 - categorical_crossentropy: 0.8649 - categorical_accuracy: 0.7755 - top_3_accuracy: 0.9113\n",
      "Epoch 00001: val_loss did not improve from 0.89437\n",
      "265/265 [==============================] - 361s 1s/step - loss: 0.8647 - categorical_crossentropy: 0.8647 - categorical_accuracy: 0.7755 - top_3_accuracy: 0.9113 - val_loss: 0.8982 - val_categorical_crossentropy: 0.8982 - val_categorical_accuracy: 0.7656 - val_top_3_accuracy: 0.9060\n",
      "Epoch 2/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8593 - categorical_crossentropy: 0.8593 - categorical_accuracy: 0.7768 - top_3_accuracy: 0.9116\n",
      "Epoch 00002: val_loss improved from 0.89437 to 0.89432, saving model to model\n",
      "265/265 [==============================] - 323s 1s/step - loss: 0.8593 - categorical_crossentropy: 0.8593 - categorical_accuracy: 0.7768 - top_3_accuracy: 0.9115 - val_loss: 0.8943 - val_categorical_crossentropy: 0.8943 - val_categorical_accuracy: 0.7693 - val_top_3_accuracy: 0.9070\n",
      "Epoch 3/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8644 - categorical_crossentropy: 0.8644 - categorical_accuracy: 0.7758 - top_3_accuracy: 0.9110\n",
      "Epoch 00003: val_loss improved from 0.89432 to 0.88485, saving model to model\n",
      "265/265 [==============================] - 323s 1s/step - loss: 0.8645 - categorical_crossentropy: 0.8645 - categorical_accuracy: 0.7758 - top_3_accuracy: 0.9110 - val_loss: 0.8849 - val_categorical_crossentropy: 0.8849 - val_categorical_accuracy: 0.7722 - val_top_3_accuracy: 0.9090\n",
      "Epoch 4/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8570 - categorical_crossentropy: 0.8570 - categorical_accuracy: 0.7777 - top_3_accuracy: 0.9119\n",
      "Epoch 00004: val_loss did not improve from 0.88485\n",
      "265/265 [==============================] - 323s 1s/step - loss: 0.8570 - categorical_crossentropy: 0.8570 - categorical_accuracy: 0.7776 - top_3_accuracy: 0.9119 - val_loss: 0.8849 - val_categorical_crossentropy: 0.8849 - val_categorical_accuracy: 0.7714 - val_top_3_accuracy: 0.9084\n",
      "Epoch 5/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8697 - categorical_crossentropy: 0.8697 - categorical_accuracy: 0.7749 - top_3_accuracy: 0.9102\n",
      "Epoch 00005: val_loss did not improve from 0.88485\n",
      "265/265 [==============================] - 359s 1s/step - loss: 0.8697 - categorical_crossentropy: 0.8697 - categorical_accuracy: 0.7749 - top_3_accuracy: 0.9103 - val_loss: 0.9592 - val_categorical_crossentropy: 0.9592 - val_categorical_accuracy: 0.7511 - val_top_3_accuracy: 0.8995\n",
      "Epoch 6/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8660 - categorical_crossentropy: 0.8660 - categorical_accuracy: 0.7756 - top_3_accuracy: 0.9108\n",
      "Epoch 00006: val_loss did not improve from 0.88485\n",
      "265/265 [==============================] - 323s 1s/step - loss: 0.8661 - categorical_crossentropy: 0.8661 - categorical_accuracy: 0.7756 - top_3_accuracy: 0.9109 - val_loss: 2.1638 - val_categorical_crossentropy: 2.1638 - val_categorical_accuracy: 0.4930 - val_top_3_accuracy: 0.7029\n",
      "Epoch 7/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8592 - categorical_crossentropy: 0.8592 - categorical_accuracy: 0.7776 - top_3_accuracy: 0.9117\n",
      "Epoch 00007: val_loss did not improve from 0.88485\n",
      "265/265 [==============================] - 323s 1s/step - loss: 0.8593 - categorical_crossentropy: 0.8593 - categorical_accuracy: 0.7775 - top_3_accuracy: 0.9117 - val_loss: 0.8931 - val_categorical_crossentropy: 0.8931 - val_categorical_accuracy: 0.7687 - val_top_3_accuracy: 0.9053\n",
      "Epoch 8/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8604 - categorical_crossentropy: 0.8604 - categorical_accuracy: 0.7766 - top_3_accuracy: 0.9114\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.88485 to 0.86987, saving model to model\n",
      "265/265 [==============================] - 362s 1s/step - loss: 0.8601 - categorical_crossentropy: 0.8601 - categorical_accuracy: 0.7767 - top_3_accuracy: 0.9114 - val_loss: 0.8699 - val_categorical_crossentropy: 0.8699 - val_categorical_accuracy: 0.7738 - val_top_3_accuracy: 0.9123\n",
      "Epoch 9/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8331 - categorical_crossentropy: 0.8331 - categorical_accuracy: 0.7832 - top_3_accuracy: 0.9148\n",
      "Epoch 00009: val_loss improved from 0.86987 to 0.83790, saving model to model\n",
      "265/265 [==============================] - 322s 1s/step - loss: 0.8334 - categorical_crossentropy: 0.8334 - categorical_accuracy: 0.7831 - top_3_accuracy: 0.9148 - val_loss: 0.8379 - val_categorical_crossentropy: 0.8379 - val_categorical_accuracy: 0.7820 - val_top_3_accuracy: 0.9147\n",
      "Epoch 10/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8389 - categorical_crossentropy: 0.8389 - categorical_accuracy: 0.7822 - top_3_accuracy: 0.9144\n",
      "Epoch 00010: val_loss did not improve from 0.83790\n",
      "265/265 [==============================] - 323s 1s/step - loss: 0.8389 - categorical_crossentropy: 0.8389 - categorical_accuracy: 0.7822 - top_3_accuracy: 0.9144 - val_loss: 0.8405 - val_categorical_crossentropy: 0.8405 - val_categorical_accuracy: 0.7836 - val_top_3_accuracy: 0.9146\n",
      "Epoch 11/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8272 - categorical_crossentropy: 0.8272 - categorical_accuracy: 0.7850 - top_3_accuracy: 0.9159\n",
      "Epoch 00011: val_loss did not improve from 0.83790\n",
      "265/265 [==============================] - 324s 1s/step - loss: 0.8271 - categorical_crossentropy: 0.8271 - categorical_accuracy: 0.7850 - top_3_accuracy: 0.9159 - val_loss: 0.8438 - val_categorical_crossentropy: 0.8438 - val_categorical_accuracy: 0.7815 - val_top_3_accuracy: 0.9137\n",
      "Epoch 12/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8187 - categorical_crossentropy: 0.8187 - categorical_accuracy: 0.7875 - top_3_accuracy: 0.9170\n",
      "Epoch 00012: val_loss improved from 0.83790 to 0.83517, saving model to model\n",
      "265/265 [==============================] - 359s 1s/step - loss: 0.8184 - categorical_crossentropy: 0.8184 - categorical_accuracy: 0.7876 - top_3_accuracy: 0.9170 - val_loss: 0.8352 - val_categorical_crossentropy: 0.8352 - val_categorical_accuracy: 0.7838 - val_top_3_accuracy: 0.9136\n",
      "Epoch 13/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.7736 - categorical_crossentropy: 0.7736 - categorical_accuracy: 0.7979 - top_3_accuracy: 0.9226\n",
      "Epoch 00013: val_loss improved from 0.83517 to 0.83046, saving model to model\n",
      "265/265 [==============================] - 320s 1s/step - loss: 0.7736 - categorical_crossentropy: 0.7736 - categorical_accuracy: 0.7978 - top_3_accuracy: 0.9226 - val_loss: 0.8305 - val_categorical_crossentropy: 0.8305 - val_categorical_accuracy: 0.7839 - val_top_3_accuracy: 0.9142\n",
      "Epoch 14/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.7782 - categorical_crossentropy: 0.7782 - categorical_accuracy: 0.7964 - top_3_accuracy: 0.9220\n",
      "Epoch 00014: val_loss did not improve from 0.83046\n",
      "265/265 [==============================] - 320s 1s/step - loss: 0.7783 - categorical_crossentropy: 0.7783 - categorical_accuracy: 0.7964 - top_3_accuracy: 0.9219 - val_loss: 0.8361 - val_categorical_crossentropy: 0.8361 - val_categorical_accuracy: 0.7819 - val_top_3_accuracy: 0.9147\n",
      "Epoch 15/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.7843 - categorical_crossentropy: 0.7843 - categorical_accuracy: 0.7952 - top_3_accuracy: 0.9214\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.83046\n",
      "265/265 [==============================] - 359s 1s/step - loss: 0.7842 - categorical_crossentropy: 0.7842 - categorical_accuracy: 0.7952 - top_3_accuracy: 0.9214 - val_loss: 0.9593 - val_categorical_crossentropy: 0.9593 - val_categorical_accuracy: 0.7486 - val_top_3_accuracy: 0.8986\n",
      "Epoch 16/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.7765 - categorical_crossentropy: 0.7765 - categorical_accuracy: 0.7970 - top_3_accuracy: 0.9223\n",
      "Epoch 00016: val_loss improved from 0.83046 to 0.81882, saving model to model\n",
      "265/265 [==============================] - 324s 1s/step - loss: 0.7764 - categorical_crossentropy: 0.7764 - categorical_accuracy: 0.7970 - top_3_accuracy: 0.9223 - val_loss: 0.8188 - val_categorical_crossentropy: 0.8188 - val_categorical_accuracy: 0.7877 - val_top_3_accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(\n",
    "    train_datagen, steps_per_epoch=STEPS, epochs=EPOCHS, verbose=1,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks = callbacks\n",
    ")\n",
    "hists.append(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "4a3a0cfef0d984d5b02872617e0eb2ad8a791964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "264/265 [============================>.] - ETA: 2s - loss: 0.8155 - categorical_crossentropy: 0.8155 - categorical_accuracy: 0.7888 - top_3_accuracy: 0.9173\n",
      "Epoch 00001: val_loss did not improve from 0.81882\n",
      "265/265 [==============================] - 556s 2s/step - loss: 0.8155 - categorical_crossentropy: 0.8155 - categorical_accuracy: 0.7887 - top_3_accuracy: 0.9173 - val_loss: 0.8262 - val_categorical_crossentropy: 0.8262 - val_categorical_accuracy: 0.7862 - val_top_3_accuracy: 0.9158\n",
      "Epoch 2/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8229 - categorical_crossentropy: 0.8229 - categorical_accuracy: 0.7875 - top_3_accuracy: 0.9162\n",
      "Epoch 00002: val_loss did not improve from 0.81882\n",
      "265/265 [==============================] - 338s 1s/step - loss: 0.8227 - categorical_crossentropy: 0.8227 - categorical_accuracy: 0.7876 - top_3_accuracy: 0.9162 - val_loss: 0.8210 - val_categorical_crossentropy: 0.8210 - val_categorical_accuracy: 0.7869 - val_top_3_accuracy: 0.9168\n",
      "Epoch 3/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8193 - categorical_crossentropy: 0.8193 - categorical_accuracy: 0.7876 - top_3_accuracy: 0.9166\n",
      "Epoch 00003: val_loss did not improve from 0.81882\n",
      "265/265 [==============================] - 343s 1s/step - loss: 0.8194 - categorical_crossentropy: 0.8194 - categorical_accuracy: 0.7876 - top_3_accuracy: 0.9165 - val_loss: 0.8317 - val_categorical_crossentropy: 0.8317 - val_categorical_accuracy: 0.7834 - val_top_3_accuracy: 0.9152\n",
      "Epoch 4/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8100 - categorical_crossentropy: 0.8100 - categorical_accuracy: 0.7898 - top_3_accuracy: 0.9179\n",
      "Epoch 00004: val_loss did not improve from 0.81882\n",
      "265/265 [==============================] - 340s 1s/step - loss: 0.8098 - categorical_crossentropy: 0.8098 - categorical_accuracy: 0.7899 - top_3_accuracy: 0.9180 - val_loss: 0.8272 - val_categorical_crossentropy: 0.8272 - val_categorical_accuracy: 0.7854 - val_top_3_accuracy: 0.9158\n",
      "Epoch 5/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8179 - categorical_crossentropy: 0.8179 - categorical_accuracy: 0.7889 - top_3_accuracy: 0.9169\n",
      "Epoch 00005: val_loss did not improve from 0.81882\n",
      "265/265 [==============================] - 339s 1s/step - loss: 0.8179 - categorical_crossentropy: 0.8179 - categorical_accuracy: 0.7889 - top_3_accuracy: 0.9169 - val_loss: 0.8210 - val_categorical_crossentropy: 0.8210 - val_categorical_accuracy: 0.7864 - val_top_3_accuracy: 0.9174\n",
      "Epoch 6/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8243 - categorical_crossentropy: 0.8243 - categorical_accuracy: 0.7863 - top_3_accuracy: 0.9159\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.81882 to 0.81688, saving model to model\n",
      "265/265 [==============================] - 340s 1s/step - loss: 0.8242 - categorical_crossentropy: 0.8242 - categorical_accuracy: 0.7863 - top_3_accuracy: 0.9159 - val_loss: 0.8169 - val_categorical_crossentropy: 0.8169 - val_categorical_accuracy: 0.7887 - val_top_3_accuracy: 0.9175\n",
      "Epoch 7/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8185 - categorical_crossentropy: 0.8185 - categorical_accuracy: 0.7870 - top_3_accuracy: 0.9168\n",
      "Epoch 00007: val_loss improved from 0.81688 to 0.81103, saving model to model\n",
      "265/265 [==============================] - 340s 1s/step - loss: 0.8185 - categorical_crossentropy: 0.8185 - categorical_accuracy: 0.7870 - top_3_accuracy: 0.9168 - val_loss: 0.8110 - val_categorical_crossentropy: 0.8110 - val_categorical_accuracy: 0.7881 - val_top_3_accuracy: 0.9177\n",
      "Epoch 8/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8130 - categorical_crossentropy: 0.8130 - categorical_accuracy: 0.7889 - top_3_accuracy: 0.9175\n",
      "Epoch 00008: val_loss improved from 0.81103 to 0.80949, saving model to model\n",
      "265/265 [==============================] - 340s 1s/step - loss: 0.8131 - categorical_crossentropy: 0.8131 - categorical_accuracy: 0.7889 - top_3_accuracy: 0.9175 - val_loss: 0.8095 - val_categorical_crossentropy: 0.8095 - val_categorical_accuracy: 0.7891 - val_top_3_accuracy: 0.9187\n",
      "Epoch 9/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8101 - categorical_crossentropy: 0.8101 - categorical_accuracy: 0.7902 - top_3_accuracy: 0.9183\n",
      "Epoch 00009: val_loss improved from 0.80949 to 0.80869, saving model to model\n",
      "265/265 [==============================] - 342s 1s/step - loss: 0.8102 - categorical_crossentropy: 0.8102 - categorical_accuracy: 0.7901 - top_3_accuracy: 0.9183 - val_loss: 0.8087 - val_categorical_crossentropy: 0.8087 - val_categorical_accuracy: 0.7901 - val_top_3_accuracy: 0.9188\n",
      "Epoch 10/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8105 - categorical_crossentropy: 0.8105 - categorical_accuracy: 0.7898 - top_3_accuracy: 0.9177\n",
      "Epoch 00010: val_loss improved from 0.80869 to 0.80765, saving model to model\n",
      "265/265 [==============================] - 341s 1s/step - loss: 0.8106 - categorical_crossentropy: 0.8106 - categorical_accuracy: 0.7898 - top_3_accuracy: 0.9177 - val_loss: 0.8077 - val_categorical_crossentropy: 0.8077 - val_categorical_accuracy: 0.7897 - val_top_3_accuracy: 0.9192\n",
      "Epoch 11/16\n",
      "264/265 [============================>.] - ETA: 1s - loss: 0.8059 - categorical_crossentropy: 0.8059 - categorical_accuracy: 0.7909 - top_3_accuracy: 0.9186"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(\n",
    "    train_datagen, steps_per_epoch=STEPS, epochs=EPOCHS, verbose=1,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks = callbacks\n",
    ")\n",
    "hists.append(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "05767778d356bc63b7cded355159fd4082eee1a5"
   },
   "outputs": [],
   "source": [
    "hist_df = pd.concat([pd.DataFrame(hist.history) for hist in hists], sort=True)\n",
    "hist_df.index = np.arange(1, len(hist_df)+1)\n",
    "fig, axs = plt.subplots(nrows=2, sharex=True, figsize=(16, 10))\n",
    "axs[0].plot(hist_df.val_categorical_accuracy, lw=5, label='Validation Accuracy')\n",
    "axs[0].plot(hist_df.categorical_accuracy, lw=5, label='Training Accuracy')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].grid()\n",
    "axs[0].legend(loc=0)\n",
    "axs[1].plot(hist_df.val_categorical_crossentropy, lw=5, label='Validation MLogLoss')\n",
    "axs[1].plot(hist_df.categorical_crossentropy, lw=5, label='Training MLogLoss')\n",
    "axs[1].set_ylabel('MLogLoss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].grid()\n",
    "axs[1].legend(loc=0)\n",
    "fig.savefig('hist.png', dpi=300)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c1927f22d3c45cba0bdee7d6f4b6c858d82d614"
   },
   "outputs": [],
   "source": [
    "valid_predictions = model.predict(x_valid, batch_size=128, verbose=1)\n",
    "map3 = mapk(valid_df[['y']].values, preds2catids(valid_predictions).values)\n",
    "print('Map3: {:.3f}'.format(map3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7d14348150baf753e90cf2719b9f31dd564f6a2"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(INPUT_DIR, 'test_simplified.csv'))\n",
    "test.head()\n",
    "x_test = df_to_image_array_xd(test, size)\n",
    "print(test.shape, x_test.shape)\n",
    "print('Test array memory {:.2f} GB'.format(x_test.nbytes / 1024.**3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "608b02f5c7909ae62becbe5c931b7264171296e8"
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(x_test, batch_size=128, verbose=1)\n",
    "\n",
    "top3 = preds2catids(test_predictions)\n",
    "top3.head()\n",
    "top3.shape\n",
    "\n",
    "cats = list_all_categories()\n",
    "id2cat = {k: cat.replace(' ', '_') for k, cat in enumerate(cats)}\n",
    "top3cats = top3.replace(id2cat)\n",
    "top3cats.head()\n",
    "top3cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52e0f9c44f2a9a38fd1550ffb9c07fb7ea22b17d"
   },
   "outputs": [],
   "source": [
    "test['word'] = top3cats['a'] + ' ' + top3cats['b'] + ' ' + top3cats['c']\n",
    "submission = test[['key_id', 'word']]\n",
    "submission.to_csv('gs_mn_submission_{}.csv'.format(int(map3 * 10**4)), index=False)\n",
    "submission.head()\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b418f4c06c4e4453aa1b5ab16dde344eb8b735c5"
   },
   "outputs": [],
   "source": [
    "end = dt.datetime.now()\n",
    "print('Latest run {}.\\nTotal time {}s'.format(end, (end - start).seconds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
